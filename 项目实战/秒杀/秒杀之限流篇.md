# 限流

**几种方法**

1. 基于合法性限流。
2. 基于负载限流。
3. 基于服务限流。
4. 基于监控限流。



## 合法性限流

- 验证码
- <font color=red>IP黑名单</font>

项目使用`redis`做了一个ip黑名单，限制同一个客户端ip在m时间片内最多请求n次

```go
const scriptBlockIP = `
if redis.call('EXISTS', KEYS[1]) == 0 then
    redis.call('SET', KEYS[1], 1)
    redis.call('EXPIRE', KEYS[1], 20)
	return true
else
	if redis.call('INCR', KEYS[1])>10 then
		return false
	else
		return true
	end
end
`
```



## 负载限流

- LVS
- <font color=red>Nginx</font>

项目使用nginx做为后端服务的反向代理，nginx使用<font color=red>轮询算法</font>分流请求到不同的服务端

```properties
upstream publish_servers {
        server publish-web-1:8080;
        server publish-web-2:8080;
        server publish-web-3:8080;
    }
```



## 服务限流

- <font color=red>控制最大连接数</font>
- <font color=red>限流算法</font>
- <font color=red>消息队列</font>
- 缓存限流



### 连接数量控制

项目在<font color=red>Nginx</font>做了连接配置，其中：

工作进程为`2`（跟cpu核数相关）

每个工作进程的最大连接数为`1024`（跟cpu性能、内存大小等有关）

```properties
worker_processes 2;

events {
    worker_connections  1024;
}
```



### 算法限流

项目使用<font color=red>漏桶算法</font>进行限流

设置最大令牌数，同时设置令牌流入速度

每次请求必须先拿到令牌才能被服务

```go
const luaScript = `
local key = KEYS[1]
local rate = tonumber(ARGV[1])
local burst = tonumber(ARGV[2])
local now = tonumber(ARGV[3])
local tokens = tonumber(redis.call('get', key) or 0)
local last = tonumber(redis.call('get', key .. ':last') or now)
local delta = math.max(now - last, 0) * rate
tokens = math.min(tokens + delta, burst)
if tokens >= 1 then
    tokens = tokens - 1
    redis.call('set', key, tokens)
    redis.call('set', key .. ':last', now)
    return true
else
    return false
end
`
```



### 消息队列缓冲

项目使用<font color=red>RabbitMQ</font>作为消息队列中间件，消息队列本质是一个可控的缓冲区，可以根据服务端的处理能力分发不同数量的消息

后端服务分两大类：生产者和消费者

**生产者**负责处理客户请求的合法性，确定请求能获取商品便会生产一条消息到队列

**消费者**负责接收队列的消息，并转化为一次购买行为



# 分布式锁

[Redis分布式锁面临的问题和解决方案 - haibiscuit - 博客园 (cnblogs.com)](https://www.cnblogs.com/haibiscuit/p/12699233.html)

秒杀系统的一个重要保障是：防止超卖

解决方案：

- 将总量分配到每个服务端上，每个服务端端维护自己的数量，可以直接加锁
- <font color=red>使用redis做分布式锁</font>



一个完整的正确的分布式锁需要解决的几个问题：

1. 锁需要保证**唯一性**。

2. 锁必须**设置过期时间**。防止业务发生错误导致死锁

3. <font color=red>锁的创建和设置锁超时时间需要具备原子性（set key value EX/PX 命令能保证）。</font>问题2的一个衍生问题，加了锁没来得及设置过期时间旧down机从而导致死锁。

4. **锁的超时问题**。当业务不能在超时时间内完成业务，锁会因为过期而释放，这时有新的线程拿到锁，就会出现多个线程同时操作共享资源的情况

   解决方案：

   - 获取锁的时候开启一个定时任务去检查过期剩余时间，及时续上过期时间，保证业务完成

     但是也不能无限制的延迟过期，总有可能还没完成业务同时也不能继续延长过期时间，这个时候还是会出现问题（待解决）

5. **谁加的锁只能谁来解**。考虑下面的场景

   A拿到锁，业务未完成，锁过期自动释放

   B拿到锁，在执行业务过程中，A完成业务后将B的锁解了，这时可能C过来加锁，这时可能就保证不了B业务的正确性

   解决方案：A解锁时先检查是不是自己的锁（uuid），是才能解锁，这能最大限度保证B的安全。

   ​                   不是的话可以选择取消这次操作或者其他更妥当的处理

   注意点：<font color=red>检查锁和解锁两个动作必须保证原子性（使用lua脚本）。</font>>假若检查了是自己的锁，但没来得及解锁，锁就过期自动解锁了，然后又会发生把其他线程的锁解了的事情

# 平滑重启

项目的生产者启动时会开启一个http服务协程和监控协程，自身做完初始化工作后则会阻塞监听信号管道等待结束或重启信号。监控协程内有一个定时任务去监控端的cpu和内存等使用情况，当出现规定次数的连续高使用率，则会主动发送<font color=red>·`SIGUSR2`</font>信号去通知主进程安全退出并fork子进程接管父进程的TCPLinstener继续监听和服务新的连接。

- 主进程接收到重启信号后，fork子进程处理新连接的同时会保证旧连接的请求都完成才会退出（这一点server.Shutdown能保证）
- 重启信号`SIGUSR2`可以来自于监控协程或操作系统的`kill -12 pid`命令



```go
var lis *net.TCPLinstener

func main(){

    var ch =make(chan os.signal)
    go monitor(ch)
    go HTTPServer(lis)
    handleSignal(ch)
}
handleSignal(ch){
    <-ch
    fork()
    return //exit 父进程
    
}
fork(){
    copy lis`s FD
    父子进程一起处理listener
}
```



# 测试

## 分布式锁（超卖问题）

不同ip的机器同时发送多次请求，对比消费者端的消费总额和redis库存的减少量

## ip黑名单

直接在浏览器连续点击请求，请求结果是：连续成功$\longrightarrow$连续失败$\longrightarrow$连续成功

## 漏桶限流

对比在不做算法限流和做了算法限流的情况下，相同时间长度内相同请求量的成功响应数目

## 平滑重启

启动生产者服务后，发送大量的请求，过程中在操作系统层面杀死父进程，查看是否能成功fork出子进程，并且查看最终请求的处理率。如果没有failed request就证明能做到平滑重启（父进程在退出前能处理完已经建立连接的请求）
